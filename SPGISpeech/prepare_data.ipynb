{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reference_path = \"./csv/train.csv\"\n",
    "val_reference_path = \"./csv/val.csv\"\n",
    "train_transcript_path = \"/home/mazhang/pt/SPGISpeech/train_transcript.json\"\n",
    "val_transcript_path = \"/home/mazhang/pt/SPGISpeech/val_transcript.json\"\n",
    "out_val_reference_path = \"./parallel_corpus/val_ref.txt\"\n",
    "out_val_input_path = \"./parallel_corpus/val_input.txt\"\n",
    "out_train_reference_path = \"./parallel_corpus/train_ref.txt\"\n",
    "out_train_input_path = \"./parallel_corpus/train_input.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(val_transcript_path, \"r\") as json_file:\n",
    "    transcript_dict = json.load(json_file)\n",
    "with open(val_reference_path, \"r\") as ref_file:\n",
    "    refs = ref_file.readlines()\n",
    "\n",
    "idx = 0\n",
    "with open(out_val_reference_path, \"w\") as out_ref_file, open(out_val_input_path, \"w\") as out_input_file:\n",
    "    for file_name, transcript in zip(transcript_dict[\"lines\"], transcript_dict[\"transcripts\"][0]):\n",
    "        audio_name = file_name.replace(\"./ITN_audio/val/\", \"\")\n",
    "        while idx<len(refs):\n",
    "            line = refs[idx]\n",
    "            if line.find(audio_name)!=-1:\n",
    "                ref = line.strip().split(\"|\")[2]\n",
    "                out_ref_file.write(ref+\"\\n\")\n",
    "                out_input_file.write(transcript+\"\\n\")\n",
    "                break\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lines', 'transcripts'])\n",
      "381102\n",
      "381102\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_transcript_1half.json\", \"r\") as first_file, open(\"train_transcript_2half.json\", \"r\") as second_file:\n",
    "    first = json.load(first_file)\n",
    "    second = json.load(second_file)\n",
    "    first[\"lines\"].extend(second[\"lines\"])\n",
    "    first[\"transcripts\"] = first[\"transcripts\"][0] + second[\"transcripts\"][0]\n",
    "    print(first.keys())\n",
    "    print(len(first[\"lines\"]))\n",
    "    print(len(first[\"transcripts\"]))\n",
    "\n",
    "with open(\"train_transcript.json\", \"w\") as file:\n",
    "    json.dump(first, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_transcript_path, \"r\") as json_file:\n",
    "    transcript_dict = json.load(json_file)\n",
    "with open(train_reference_path, \"r\") as ref_file:\n",
    "    refs = ref_file.readlines()\n",
    "\n",
    "idx = 0\n",
    "with open(out_train_reference_path, \"w\") as out_ref_file, open(out_train_input_path, \"w\") as out_input_file:\n",
    "    for file_name, transcript in zip(transcript_dict[\"lines\"], transcript_dict[\"transcripts\"]):\n",
    "        audio_name = file_name.replace(\"./ITN_audio/train/\", \"\")\n",
    "        while idx<len(refs):\n",
    "            line = refs[idx]\n",
    "            if line.find(audio_name)!=-1:\n",
    "                ref = line.strip().split(\"|\")[2]\n",
    "                out_ref_file.write(ref+\"\\n\")\n",
    "                out_input_file.write(transcript+\"\\n\")\n",
    "                break\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ref_prep_path = \"./parallel_corpus/val_ref_prep.txt\"\n",
    "train_ref_prep_path = \"./parallel_corpus/train_ref_prep.txt\"\n",
    "# add spaces around the symbols\n",
    "with open(out_train_reference_path, \"r\") as file, open(train_ref_prep_path, \"w\") as out_file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        new_line = \"\"\n",
    "        for idx, char in enumerate(line):\n",
    "            if not char.isalnum() and not char.isspace() and (idx == len(line)-1 or line[idx+1].isspace() or char in \"'%-?!\"):\n",
    "                new_line += \" \" + char\n",
    "                if char != \"'\":\n",
    "                    new_line += \" \"\n",
    "            else:\n",
    "                new_line += char\n",
    "        new_line = re.sub(r\"\\s+\", \" \", new_line)\n",
    "        new_line = re.sub(r\"n 't\", r\" n't\", new_line)\n",
    "        out_file.write(new_line + \"\\n\")\n",
    "\n",
    "with open(out_val_reference_path, \"r\") as file, open(val_ref_prep_path, \"w\") as out_file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        new_line = \"\"\n",
    "        for idx, char in enumerate(line):\n",
    "            if not char.isalnum() and not char.isspace() and (idx == len(line)-1 or line[idx+1].isspace() or char in \"'%-?!\"):\n",
    "                new_line += \" \" + char\n",
    "                if char != \"'\":\n",
    "                    new_line += \" \"\n",
    "            else:\n",
    "                new_line += char\n",
    "        new_line = re.sub(r\"\\s+\", \" \", new_line)\n",
    "        new_line = re.sub(r\"n 't\", r\" n't\", new_line)\n",
    "        out_file.write(new_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_prep_path = \"./parallel_corpus/train_input.prep.txt\"\n",
    "val_input_prep_path = \"./parallel_corpus/val_input.prep.txt\"\n",
    "train_input_path = \"./parallel_corpus/train_input_TN.txt\"\n",
    "val_input_path = \"./parallel_corpus/val_input_TN.txt\"\n",
    "# remove all symbols except '\n",
    "with open(train_input_path, \"r\") as file, open(train_input_prep_path, \"w\") as out_file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        new_line = line.replace(\",\", \"\").replace(\".\", \"\").replace(\"?\", \"\").replace(\"-\", \" \")\n",
    "        new_line = re.sub(r\"\\s+\", \" \", new_line)\n",
    "        out_file.write(new_line + \"\\n\")\n",
    "\n",
    "with open(val_input_path, \"r\") as file, open(val_input_prep_path, \"w\") as out_file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        new_line = line.replace(\",\", \"\").replace(\".\", \"\").replace(\"?\", \"\").replace(\"-\", \" \")\n",
    "        new_line = re.sub(r\"\\s+\", \" \", new_line)\n",
    "        out_file.write(new_line + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
