# Introduction
This folder presents the code to train, fine-tune and evaluate denormalization models. Most codes are adopted from [link](https://github.com/spitch-oss/denormalizer).

# Directory Structure
- **checkpoints/**: the model checkpoints.

- **data-bin/**: contains the bpe-code, transformed train/valid/test data ready for the model to train. 

- **eval/**: the evaluation scripts and data

- **model_outputs/**: contains the hypothesis generated by the model and respective evaluation reports.

- **scripts/**: Mainly from the original github repo. Contains all the major scripts for training.

# Runing code:
First, create and activate a virtual environment. 
```
conda env create -f environment.yml
conda activate denor
```

## Evaluation
check eval/run_eval.sh for examples of runing evaluation on various models with different data

## Training
To train denormalization model on GTN dataset, run:
```
bash train_denormalizer.sh {data_directory}
```
The data_directory is the path to the GTN training split. Remeber to seperate the training split from other files. This preprocesses the data and trains the model with default parameters

To train denormalization model on any other dataset, prepare the data first. We need to have 6 data files which include:
- train.raw.{source}
- train.raw.{target}
- valid.raw.{source}
- valid.raw.{target}
- test.raw.{source}
- test.raw.{target}

The source files are the input to the model. The target files are the expected output. You can replace {source} and {target} with any string, but you need to specify the parameters accordingly. 

To run the training:
```
bash train_on_any.sh -s {source} -t {target} -o {output_dir} {data_dir}
```
Change the parameters accordingly. 

## Finetuning
Finetuning is like the training, but we need to reuse the bpe-codes of the pretraining dataset. 

First copy the bpe-code into the denormalizer folder, then change the parameters in finetune.sh accordingly. Finally run:
```
bash finetune.sh
```

# model checkpoints and data
- GTN_train/GTN_0to89: GTN dataset
- SPGI_TN: SPGI dataset
- ft_SPGI_TN/ft_SPGI_TN_prime: First pretrain on GTN then finetune on SPGI, prime means hyperparameter tuning
- GTN_SPGI: trained on GTN sampled subset and SPGI dataset
- GTNaisg_SPGI: combined dataset from aisg and SPGI dataset.
