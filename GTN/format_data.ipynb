{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = [\"95\", \"96\", \"97\", \"98\", \"99\"]\n",
    "classes = [\"LETTERS\", \"CARDINAL\", \"VERBATIM\", \"ORDINAL\", \"DECIMAL\", \"DIGIT\", \"MONEY\", \"FRACTION\", \"TIME\", \"ADDRESS\"]\n",
    "counter = {x:0 for x in classes}\n",
    "desired_samples = 1000\n",
    "classes_to_sample = classes\n",
    "\n",
    "written_len = 0\n",
    "spoken_len = 0\n",
    "\n",
    "for item in item_list: \n",
    "    with open(f\"output-000{item}-of-00100\", \"r\") as file:\n",
    "        sentence_written_list = []\n",
    "        sentence_spoken_list = []\n",
    "        sentence_written = \"\"\n",
    "        sentence_spoken = \"\"\n",
    "        flag = False\n",
    "        \n",
    "        for line in file:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            fields = line.split(\"\\t\")\n",
    "            if not fields[1].isascii():\n",
    "                flag = True\n",
    "            if len(fields)==2:\n",
    "                if flag or len(sentence_spoken)>=1024:\n",
    "                    flag = False\n",
    "                    # print(\"discarded line: \", sentence_written)\n",
    "                    sentence_written = \"\"\n",
    "                    sentence_spoken = \"\"\n",
    "                    continue\n",
    "                \n",
    "                temp = \"\"\n",
    "                for i, char in enumerate(sentence_written):\n",
    "                    if char in \",.'-%\" and i>0 and sentence_written[i-1]!=\" \":\n",
    "                        temp += \" \" + char\n",
    "                    else:\n",
    "                        temp += char\n",
    "                    if char in \".,\" and i<len(sentence_written)-1 and sentence_written[i+1] != \" \":\n",
    "                        temp += \" \"\n",
    "                sentence_written = temp\n",
    "                sentence_written_list.append(sentence_written)\n",
    "                sentence_spoken_list.append(sentence_spoken)\n",
    "                sentence_written = \"\"\n",
    "                sentence_spoken = \"\"\n",
    "            elif len(fields)==3:\n",
    "                seperator = \" \"\n",
    "                # seperator = \"\"\n",
    "                # if len(sentence_spoken) != 0 and fields[2] != \"sil\":\n",
    "                #     seperator = \" \"\n",
    "                ignored_symbols = ['\"', \"(\", \")\"]\n",
    "                if fields[1] in ignored_symbols: # discard ignored symbols\n",
    "                    continue\n",
    "                sentence_written += seperator + fields[1]\n",
    "                if fields[2] == \"<self>\": # copy words\n",
    "                    sentence_spoken += seperator + fields[1].casefold()\n",
    "                elif fields[2] == \"sil\":\n",
    "                    pass\n",
    "                elif fields[0] == \"ELECTRONIC\":\n",
    "                    components = fields[2].split(\" _letter \")\n",
    "                    components = [c.replace(\"_letter\", \"\").replace(\" \", \"\") for c in components]\n",
    "                    newspoken = \" \".join(components).replace(\"dot\", \" dot \")\n",
    "                    sentence_spoken += seperator + newspoken.casefold()\n",
    "                else:\n",
    "                    sentence_spoken += seperator + fields[2].casefold()\n",
    "            \n",
    "        spoken_len += len(sentence_spoken_list)\n",
    "        with open(\"test_spoken.txt\", \"a\") as file:\n",
    "            for sentence in sentence_spoken_list:\n",
    "                file.write(sentence+\"\\n\")\n",
    "\n",
    "        written_len += len(sentence_written_list)\n",
    "        with open(\"test_written.txt\", \"a\") as file:\n",
    "            for sentence in sentence_written_list:\n",
    "                file.write(sentence+\"\\n\")\n",
    "            \n",
    "\n",
    "print(\"length of spoken sentence list: \", spoken_len)\n",
    "print(\"length of written sentence list: \", written_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_remove = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_spoken.txt\", \"r\") as file1, open(\"test_written.txt\", \"r\") as file2:\n",
    "    for idx, (spoken, written) in enumerate(zip(file1, file2)):\n",
    "        if len(spoken)>1024:\n",
    "            print(idx, spoken.replace(\"\\n\", \"\"))\n",
    "            print(idx, written.replace(\"\\n\", \"\"))\n",
    "            index_remove.add(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_written.txt\", \"r\") as file:\n",
    "    for idx, line in enumerate(file):\n",
    "        if len(line)>1500:\n",
    "            print(idx, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4290238\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_written.txt\", \"r\") as file:\n",
    "    print(len(file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4290238\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_spoken.txt\", \"r\") as file:\n",
    "    print(len(file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 0\n",
      "reading 1\n",
      "reading 2\n",
      "reading 3\n",
      "reading 4\n",
      "reading 5\n",
      "reading 6\n",
      "reading 7\n",
      "reading 8\n",
      "reading 9\n",
      "reading 10\n",
      "reading 11\n",
      "reading 12\n",
      "reading 13\n",
      "reading 14\n",
      "reading 15\n",
      "reading 16\n",
      "reading 17\n",
      "reading 18\n",
      "reading 19\n",
      "reading 20\n",
      "reading 21\n",
      "reading 22\n",
      "reading 23\n",
      "reading 24\n",
      "reading 25\n",
      "reading 26\n",
      "reading 27\n",
      "reading 28\n",
      "reading 29\n",
      "reading 30\n",
      "reading 31\n",
      "reading 32\n",
      "reading 33\n",
      "reading 34\n",
      "reading 35\n",
      "reading 36\n",
      "reading 37\n",
      "reading 38\n",
      "reading 39\n",
      "reading 40\n",
      "reading 41\n",
      "reading 42\n",
      "reading 43\n",
      "reading 44\n",
      "reading 45\n",
      "reading 46\n",
      "reading 47\n",
      "reading 48\n",
      "reading 49\n",
      "reading 50\n",
      "reading 51\n",
      "reading 52\n",
      "reading 53\n",
      "reading 54\n",
      "reading 55\n",
      "reading 56\n",
      "reading 57\n",
      "reading 58\n",
      "reading 59\n",
      "reading 60\n",
      "reading 61\n",
      "reading 62\n",
      "reading 63\n",
      "reading 64\n",
      "reading 65\n",
      "reading 66\n",
      "reading 67\n",
      "reading 68\n",
      "reading 69\n",
      "reading 70\n",
      "reading 71\n",
      "reading 72\n",
      "reading 73\n",
      "reading 74\n",
      "reading 75\n",
      "reading 76\n",
      "reading 77\n",
      "reading 78\n",
      "reading 79\n",
      "reading 80\n",
      "reading 81\n",
      "reading 82\n",
      "reading 83\n",
      "reading 84\n",
      "reading 85\n",
      "reading 86\n",
      "reading 87\n",
      "reading 88\n",
      "reading 89\n"
     ]
    }
   ],
   "source": [
    "start_idx = 0\n",
    "end_idx = 89\n",
    "counter = 0\n",
    "for idx in range(start_idx, end_idx+1):\n",
    "    print(f\"reading {idx}\")\n",
    "    with open(\"output-000{:0>2d}-of-00100\".format(idx), \"r\") as file:\n",
    "        non_ascii_flag = False\n",
    "        ITN_flag = False\n",
    "        for line in file:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            fields = line.split(\"\\t\")\n",
    "            if not fields[1].isascii():\n",
    "                non_ascii_flag = True\n",
    "            if len(fields)==2:\n",
    "                if non_ascii_flag:\n",
    "                    non_ascii_flag = False\n",
    "                elif ITN_flag:\n",
    "                    counter += 1\n",
    "                    ITN_flage = False\n",
    "\n",
    "            elif len(fields)==3:\n",
    "                if fields[2] != \"<self>\" and fields[2] != \"sil\": # copy words\n",
    "                    ITN_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77244691"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formating aisg data into parallel corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"AISG/final_train.tsv\"\n",
    "valid_file_path = \"AISG/validation.tsv\"\n",
    "test_file_path = \"AISG/hard_test_set.tsv\"\n",
    "processed_train_spoken_file_path = \"AISG/processed/train_spoken.txt\"\n",
    "processed_train_written_file_path = \"AISG/processed/train_written.txt\"\n",
    "processed_valid_spoken_file_path = \"AISG/processed/valid_spoken.txt\"\n",
    "processed_valid_written_file_path = \"AISG/processed/valid_written.txt\"\n",
    "processed_test_spoken_file_path = \"AISG/processed/test_spoken.txt\"\n",
    "processed_test_written_file_path = \"AISG/processed/test_written.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ', '\"', '!', '€', '/', '[', '+', '.', '_', '#', ')', '?', '(', '-', ',', '&', '%', ':', ';', '$', '>', '£', \"'\", 'µ', '¥', '~', ']', 'Ω', '<'}\n",
      "{' ', '\"', '!', '€', '/', '[', '+', '.', '_', '#', ')', '?', '(', '-', '}', ',', '&', '%', 'α', ':', ';', '$', '>', '£', \"'\", 'µ', '¥', '~', ']', 'Ω', '<', 'ˈ', '{'}\n",
      "{' ', '\"', '!', '€', '/', '[', '+', '.', '_', '#', ')', '?', '(', '-', '}', ',', '&', '%', 'α', ':', ';', '$', '>', '£', \"'\", 'µ', '¥', '~', ']', 'Ω', '<', 'ˈ', '{'}\n"
     ]
    }
   ],
   "source": [
    "# check the symbols and non ascii characters in the dataset\n",
    "symbols = set()\n",
    "with open(train_file_path, \"r\") as train_file, open(valid_file_path, \"r\") as valid_file, open(test_file_path, \"r\") as test_file:\n",
    "    for line in train_file:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        text = line[1]\n",
    "        for char in text:\n",
    "            if not char.isalnum() or not char.isascii():\n",
    "                symbols.add(char)\n",
    "    print(symbols)\n",
    "    \n",
    "    for line in valid_file:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        text = line[1]\n",
    "        for char in text:\n",
    "            if not char.isalnum() or not char.isascii():\n",
    "                symbols.add(char)\n",
    "    print(symbols)\n",
    "\n",
    "    for line in test_file:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        text = line[1]\n",
    "        for char in text:\n",
    "            if not char.isalnum() or not char.isascii():\n",
    "                symbols.add(char)\n",
    "    print(symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parallel_corpus(input_file, s_file, w_file, sentence_limit=-1):\n",
    "    symbols_to_remove = \"[]{}():\\\"'<>\" # symbols to remove when acting as punctuation\n",
    "    sentence_written_list = []\n",
    "    sentence_spoken_list = []\n",
    "    sentence_written = []\n",
    "    sentence_spoken = []\n",
    "    count = 0\n",
    "\n",
    "    for line in input_file:\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "\n",
    "        if fields[0] == \"<eos>\":\n",
    "            if len(sentence_spoken)>=128:\n",
    "                sentence_written = []\n",
    "                sentence_spoken = []\n",
    "                continue\n",
    "            \n",
    "            sentence_written = \" \".join(sentence_written)\n",
    "            sentence_spoken = \" \".join(sentence_spoken)\n",
    "            sentence_written_list.append(sentence_written)\n",
    "            sentence_spoken_list.append(sentence_spoken)\n",
    "            sentence_written = []\n",
    "            sentence_spoken = []\n",
    "\n",
    "            count += 1\n",
    "            if sentence_limit!=-1 and count == sentence_limit:\n",
    "                break\n",
    "\n",
    "        elif fields[0] == \"PUNCT\":\n",
    "            if fields[1] in symbols_to_remove: # discard ignored symbols\n",
    "                continue\n",
    "            sentence_written.append(fields[1])\n",
    "        elif fields[2] == \"<self>\":\n",
    "            # copy words \n",
    "            sentence_spoken.append(fields[1].casefold())\n",
    "            sentence_written.append(fields[1])\n",
    "        else:\n",
    "            sentence_spoken.append(fields[2])\n",
    "            sentence_written.append(fields[1])\n",
    "    \n",
    "    for sen in sentence_spoken_list:\n",
    "        s_file.write(sen + \"\\n\")\n",
    "    for sen in sentence_written_list:\n",
    "        w_file.write(sen + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_file_path, \"r\") as input_file, \\\n",
    "    open(processed_train_spoken_file_path, \"w\") as s_file, \\\n",
    "    open(processed_train_written_file_path, \"w\") as w_file:\n",
    "\n",
    "    get_parallel_corpus(input_file, s_file, w_file)\n",
    "\n",
    "with open(valid_file_path, \"r\") as input_file, \\\n",
    "    open(processed_valid_spoken_file_path, \"w\") as s_file, \\\n",
    "    open(processed_valid_written_file_path, \"w\") as w_file:\n",
    "\n",
    "    get_parallel_corpus(input_file, s_file, w_file, sentence_limit=40000)\n",
    "\n",
    "with open(test_file_path, \"r\") as input_file, \\\n",
    "    open(processed_test_spoken_file_path, \"w\") as s_file, \\\n",
    "    open(processed_test_written_file_path, \"w\") as w_file:\n",
    "\n",
    "    get_parallel_corpus(input_file, s_file, w_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
